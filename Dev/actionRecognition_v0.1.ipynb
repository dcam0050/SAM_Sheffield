{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import readline\n",
    "import GPy\n",
    "from SAM.SAM_Core import SAMCore\n",
    "from SAM.SAM_Core import SAMDriver\n",
    "import pylab as pb\n",
    "import sys \n",
    "from sys import executable\n",
    "import subprocess\n",
    "from subprocess import Popen, PIPE\n",
    "import pickle\n",
    "import os\n",
    "from os import listdir, walk, system\n",
    "from os.path import isfile, join, isdir\n",
    "import time\n",
    "import operator\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import datetime\n",
    "import yarp\n",
    "import copy\n",
    "from itertools import combinations \n",
    "from ConfigParser import SafeConfigParser\n",
    "from scipy.spatial import distance\n",
    "from numpy.linalg import inv\n",
    "import math\n",
    "\n",
    "dataSetFolder = '/home/daniel/WYSIWYD_PROJECT/actionRecognitionDataset'\n",
    "dataFolderList = ['lift-drop-right_arm', \n",
    "                  'lift-drop-left_arm', \n",
    "                  'push-pull-left_arm', \n",
    "                  'push-pull-right_arm']\n",
    "\n",
    "dataFolders = []\n",
    "labelFolders = []\n",
    "#check folders in list actually exist\n",
    "for j in dataFolderList:\n",
    "    t = join(dataSetFolder,j,'data')\n",
    "    m = join(dataSetFolder,j,'labels')\n",
    "    if(isdir(t) and isdir(m)):\n",
    "        dataFolders.append(t)\n",
    "        labelFolders.append(m)\n",
    "print '\\n'.join(dataFolders)\n",
    "print\n",
    "print '\\n'.join(labelFolders)\n",
    "#subDirFolderList = ['camera/left', 'camera/right', 'data', 'kinect/rgb', 'labels']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load kinect skeleton data for all folders in dataFolderList\n",
    "numJoints = 9\n",
    "data = dict()\n",
    "firstPass = True\n",
    "jointsList = []\n",
    "objectsList = []\n",
    "labelsList = []\n",
    "numFolders = len(dataFolders)\n",
    "\n",
    "for j in dataFolders:\n",
    "    k = dataFolders.index(j)\n",
    "    dataFile = open(join(dataFolders[k],'data.log'),'r')\n",
    "    labelFile = open(join(labelFolders[k],'data.log'),'r')\n",
    "    \n",
    "    #number of lines in dataFile\n",
    "    for i, l in enumerate(dataFile):\n",
    "            pass\n",
    "    lenDataFile = i+1\n",
    "    \n",
    "    #number of lines in labelFile\n",
    "    for i, l in enumerate(labelFile):\n",
    "            pass\n",
    "    lenLabelFile = i+1\n",
    "    dataFile.close()\n",
    "    labelFile.close()\n",
    "    \n",
    "    \n",
    "    if(lenLabelFile != lenDataFile):\n",
    "        raise ValueError('Files not of same lenght')\n",
    "    else:\n",
    "        dataFile = open(join(dataFolders[k],'data.log'),'r')\n",
    "        labelFile = open(join(labelFolders[k],'data.log'),'r')\n",
    "        labelsList.append([])\n",
    "        \n",
    "        for curr in range(lenDataFile):\n",
    "            line = dataFile.readline()\n",
    "            labelLine = labelFile.readline()\n",
    "            \n",
    "            t = line.replace('(','').replace(')','').split(' ')\n",
    "            del t[0:4]\n",
    "            #parse skeleton data which has 9 sections by (x,y,z)\n",
    "            for i in range(numJoints):\n",
    "                a = i*4\n",
    "                if(firstPass):\n",
    "                    data[t[a]] = [None]*numFolders\n",
    "                    data[t[a]][k] = (np.array([float(t[a+1]), float(t[a+2]), float(t[a+3])]))\n",
    "                    jointsList.append(t[a])\n",
    "                else:\n",
    "                    arr =  np.array([float(t[a+1]), float(t[a+2]), float(t[a+3])])\n",
    "                    if(data[t[a]][k] != None):\n",
    "                        data[t[a]][k] = np.vstack((data[t[a]][k],arr))\n",
    "                    else:\n",
    "                        data[t[a]][k] = arr\n",
    "\n",
    "            currIdx = (numJoints*4 -1)\n",
    "            numObjs = (len(t) - currIdx)/5\n",
    "\n",
    "            for i in range(numObjs):\n",
    "                a = currIdx + 1 + (i*5)\n",
    "                if(t[a] in data):\n",
    "                    arr = np.array([float(t[a+1]), float(t[a+2]), float(t[a+3])])\n",
    "                    if(data[t[a]][k] != None):\n",
    "                        data[t[a]][k] =  np.vstack((data[t[a]][k],arr))\n",
    "                    else:\n",
    "                        data[t[a]][k] = arr\n",
    "                else:\n",
    "                    data[t[a]] = [None]*(numFolders+1)\n",
    "                    data[t[a]][k] = np.array([float(t[a+1]), float(t[a+2]), float(t[a+3])])\n",
    "                    data[t[a]][-1] = int(t[a+4])\n",
    "                    objectsList.append(t[a])\n",
    "\n",
    "            firstPass = False\n",
    "            try:\n",
    "                v = labelLine.split(' ')[2].replace('\\n','').replace('(','').replace(')','')\n",
    "            except IndexError:\n",
    "                print labelLine\n",
    "                \n",
    "            labelsList[k].append(v)\n",
    "            \n",
    "        dataFile.close()\n",
    "        labelFile.close()\n",
    "\n",
    "#compile a list of all unique labels\n",
    "setList = []\n",
    "for x in labelsList:\n",
    "    setList.append(list(set(x)))\n",
    "flattenedList = [val for sublist in setList for val in sublist]\n",
    "labels = list(set(flattenedList))\n",
    "labels.sort()\n",
    "for k in range(0,len(labels)):\n",
    "    print str(k) + '  ' + labels[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#prepare list of indices for labels which will be used\n",
    "ignoreInds = [1,2,9] #agent_entry, agent_exit, no_agent\n",
    "#important that no other labels are removed because that would interfere with temporal continuity of data\n",
    "#no temporal continuity would make QTC calculation with big jumps which is not desirable\n",
    "#future work needs to go through data and split it into subsections depending on actions to be considered\n",
    "\n",
    "doLabels = [x for i,x in enumerate(labels) if i not in ignoreInds]\n",
    "indicesList = []\n",
    "for ll in labelsList:\n",
    "    indicesList.append([i for i, x in enumerate(ll) if x in doLabels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#apply indices\n",
    "subsetData = None\n",
    "subsetLabels = None\n",
    "subsetData = copy.deepcopy(data)\n",
    "subsetLabels = copy.deepcopy(labelsList)\n",
    "\n",
    "for k in range(numFolders):\n",
    "    for j in jointsList + objectsList:\n",
    "        subsetData[j][k] = np.squeeze(data[j][k][[indicesList[k]],:])\n",
    "        subsetLabels[k] = [labelsList[k][i] for i in indicesList[k]]\n",
    "# data = None\n",
    "# labelsList = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#apply indices\n",
    "count = 0\n",
    "off1 = 3\n",
    "off2 = 2\n",
    "off3 = 15\n",
    "off4 = 25\n",
    "for k in range(numFolders):\n",
    "    for j in jointsList + objectsList:\n",
    "        count += 1\n",
    "        print str(count).ljust(off1) + ' Folder ' + str(k).ljust(off2) + ' object: ' + j.ljust(off3) + \\\n",
    "        ' data shape: '.ljust(off4) + str(len(data)) + ' ' + str(len(data[j])) + ' ' + str(data[j][k].shape)\n",
    "        print str(count).ljust(off1) + ' Folder ' + str(k).ljust(off2) + ' object: ' + j.ljust(off3) + \\\n",
    "        ' subset data shape: '.ljust(off4) + str(len(subsetData)) + ' ' + str(len(subsetData[j])) + ' ' + str(subsetData[j][k].shape)\n",
    "        print str(count).ljust(off1) + ' Folder ' + str(k).ljust(off2) + ' object: ' + j.ljust(off3) + \\\n",
    "        ' labels shape: '.ljust(off4) + str(len(labelsList)) + '     ' + str(len(labelsList[k]))\n",
    "        print str(count).ljust(off1) + ' Folder ' + str(k).ljust(off2) + ' object: ' + j.ljust(off3) + \\\n",
    "        ' subset labels shape: '.ljust(off4) + str(len(subsetLabels)) + '     ' + str(len(subsetLabels[k]))\n",
    "        print str(count).ljust(off1) + ' Folder ' + str(k).ljust(off2) + ' object: ' + j.ljust(off3) + \\\n",
    "        ' good inds shape: '.ljust(off4) + str(len(indicesList)) + '     ' + str(len(indicesList[k]))\n",
    "        print\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#so far the data has been first formatted into a dictionary for the joints and objects with each key holding\n",
    "#numFolders numpyarrays, one for each data folder. labels are formatted into a list with numFolders lenght\n",
    "#no_agent, agent_entry and agent_exit have been removed and the remaining data stored in subsetData, subsetLabels\n",
    "#next step create combinatorial pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "allObjs = jointsList + objectsList\n",
    "print '\\n'.join(allObjs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#select which combinations are importantd\n",
    "#shoulderCentre-handLeft shoulderCentre-handRight handLeft-activeObject handRight-activeObject\n",
    "\n",
    "#remove items wich are not important\n",
    "impObjs = copy.deepcopy(allObjs)\n",
    "\n",
    "remObjs = ['partner','car','octopus']\n",
    "\n",
    "for x in remObjs:\n",
    "    impObjs.remove(x)\n",
    "print '\\n'.join(impObjs)\n",
    "print \n",
    "objCombs = list(combinations(impObjs, 2))\n",
    "print objCombs\n",
    "print len(objCombs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def distEuc(a,b):\n",
    "    temp = a-b\n",
    "    temp = np.square(temp)\n",
    "    temp = np.sum(temp,1)\n",
    "    return np.sqrt(temp)\n",
    "\n",
    "def qtc_2D(k,l,q,thresh, contactThresh, contact = None):\n",
    "    \n",
    "    d1 = distEuc(k[:-2],l[1:-1])\n",
    "    d2 = distEuc(k[1:-1],l[1:-1])\n",
    "    d3 = distEuc(k[2:],l[1:-1])\n",
    "    \n",
    "    func2 = 0\n",
    "    if(func2 == 0):\n",
    "        for i in range(len(d1)):\n",
    "            #threshold distance moved\n",
    "            diff1 = d2[i]-d1[i]\n",
    "            if(np.abs(diff1) < thresh):\n",
    "                diff1 = 0\n",
    "\n",
    "            diff2 = d3[i]-d2[i]\n",
    "            if(np.abs(diff2) < thresh):\n",
    "                diff2 = 0\n",
    "\n",
    "            #convert to qtc\n",
    "            if(diff1 > 0 and diff2 > 0):\n",
    "                q[i] = -1\n",
    "            elif(diff1 < 0 and diff2 < 0):\n",
    "                q[i] = +1\n",
    "            else:\n",
    "                q[i] = 0\n",
    "                \n",
    "    elif(func2 == 1):\n",
    "            #threshold distances\n",
    "        inds = d1 < thresh\n",
    "        d1[inds] = 0\n",
    "\n",
    "        inds = d2 < thresh\n",
    "        d2[inds] = 0\n",
    "\n",
    "        inds = d3 < thresh\n",
    "        d3[inds] = 0\n",
    "\n",
    "        for i in range(len(d1)):\n",
    "            if(d1[i] < d2[i] < d3[i]):\n",
    "                q[i] = -1\n",
    "            elif(d1[i] > d2[i] > d3[i]):\n",
    "                q[i] = +1\n",
    "            else:\n",
    "                q[i] = 0\n",
    "        \n",
    "        #check contact\n",
    "        \n",
    "        #check qtc smoothness\n",
    "\n",
    "def frenetFrame(arr):\n",
    "    t_num = np.diff(arr,axis=0)\n",
    "    t = (t_num/np.abs(t_num)).astype(int)\n",
    "\n",
    "    b_num = np.cross(t[:-1],t[1:])\n",
    "    b = b_num/np.abs(b_num)\n",
    "    t = t[1:]\n",
    "\n",
    "    n = np.cross(b,t)\n",
    "\n",
    "    frameArr = np.concatenate((t,n,b),axis=1).T\n",
    "    fArr = frameArr.reshape((3,3,-1),order = 'F')\n",
    "    return fArr\n",
    "\n",
    "def qtc_3D(k, l, thresh, q3, q4, q5):\n",
    "    fFrameK = frenetFrame(k)\n",
    "    fFrameL = frenetFrame(l)\n",
    "\n",
    "    for g in range(fFrameK.shape[2]):\n",
    "        fKinv = np.linalg.pinv(fFrameK[:,:,g])\n",
    "        R = np.dot(fFrameL[:,:,g],fKinv)\n",
    "        \n",
    "        alpha = np.arctan(R[1,0]/R[0,0])\n",
    "        den = np.sqrt(pow(R[2,1],2) + pow(R[2,2],2))\n",
    "        \n",
    "        beta = np.arctan(-R[2,0]/den)\n",
    "        gamma = np.arctan(R[2,1]/R[2,2])\n",
    "\n",
    "        #threshold angles\n",
    "        if(np.abs(alpha) < thresh or math.isnan(alpha)):\n",
    "            alpha = 0\n",
    "        if(np.abs(beta) < thresh or math.isnan(beta)):\n",
    "            beta = 0\n",
    "        if(np.abs(gamma) < thresh or math.isnan(gamma)):\n",
    "            gamma = 0\n",
    "\n",
    "        q3[g] = np.sign(alpha)\n",
    "        q4[g] = np.sign(beta)\n",
    "        q5[g] = np.sign(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "qtcDataList = dict()\n",
    "angleThreshold = 0.1\n",
    "distanceThreshold = 0.001\n",
    "contactThreshold = 0.01\n",
    "allJoints = []\n",
    "#for all combs\n",
    "for arr in range(len(subsetData[objCombs[0][0]])):\n",
    "    jointArr = None\n",
    "    for currComb in objCombs:\n",
    "        Pk = subsetData[currComb[0]]\n",
    "        Pl = subsetData[currComb[1]]\n",
    "        #for all arrays in Pk and Pl\n",
    "        currPk = Pk[arr]\n",
    "        currPl = Pl[arr]\n",
    "\n",
    "        q1 = np.zeros(currPk.shape[0]-2, dtype=np.int)\n",
    "        q2 = np.zeros(currPk.shape[0]-2, dtype=np.int)\n",
    "        q3 = np.zeros(currPk.shape[0]-2, dtype=np.int)\n",
    "        q4 = np.zeros(currPk.shape[0]-2, dtype=np.int)\n",
    "        q5 = np.zeros(currPk.shape[0]-2, dtype=np.int)\n",
    "        #currPk contains xyz and currPl contains xyz\n",
    "        #calculate QTC\n",
    "        #step 1: q1 = {-1,0,+1} Pk relative to Pl\n",
    "        qtc_2D(currPk,currPl,q1, distanceThreshold, contactThreshold)\n",
    "        #step 2: q2 = {-1,0,+1} Pl relative to Pk\n",
    "        qtc_2D(currPl,currPk,q2, distanceThreshold, contactThreshold)\n",
    "        #step 3: calculate q3, q4 and q5\n",
    "        qtc_3D(currPk, currPl, angleThreshold, q3, q4, q5)\n",
    "\n",
    "        tempArr = np.vstack((q1,q2,q3,q4,q5))\n",
    "        if(jointArr == None):\n",
    "            jointArr = tempArr.T\n",
    "        else:\n",
    "            jointArr = np.hstack((jointArr,tempArr.T))\n",
    "    allJoints.append(jointArr)\n",
    "    \n",
    "    #updating labels\n",
    "    subsetLabels[arr] = subsetLabels[arr][1:-1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mask = np.zeros(allJoints[0].shape[1], dtype = int)\n",
    "for i in range(0,len(mask),5):\n",
    "    mask[i+0] = 1\n",
    "    mask[i+1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "actionsIdxList = []\n",
    "actionsLabelsList = []\n",
    "\n",
    "#for each item in list\n",
    "for k in range(len(allJoints)):\n",
    "    actionsIdxList.append([])\n",
    "    actionsLabelsList.append([])\n",
    "    #create array that masks q2,q3 and q4\n",
    "    maJoints = allJoints[k]*mask\n",
    "    #sum abs(rows) of array\n",
    "    maAbs = np.abs(maJoints)\n",
    "    maSum = np.sum(maAbs, axis = 1)\n",
    "    #indices with maAbs =  0 are regions with no movement \n",
    "    #.ie action demarcation between actions\n",
    "    #maSum = maSum[:50]\n",
    "    actionCount = 0\n",
    "    actionsIndices = None\n",
    "    actionsLabels = []\n",
    "    started = False\n",
    "    for n in range(len(maSum)):\n",
    "        if(maSum[n] == 0):\n",
    "            #here we need to close action if previous is not zero\n",
    "            #start action if next is not zero\n",
    "            #ignore otherwise\n",
    "\n",
    "            #if n-1 not 0 end action\n",
    "            #check n-1 exists \n",
    "            if(n-1 >= 0):\n",
    "                if(maSum[n-1] != 0):\n",
    "                    #end action including 0 at n\n",
    "                    actionsIndices = np.hstack((actionsIndices, allJoints[k][n]))\n",
    "                    actionsLabels.append(subsetLabels[k][n])\n",
    "                    started = False\n",
    "                    actionsIdxList[k].append(actionsIndices)\n",
    "                    actionsLabelsList[k].append(actionsLabels)\n",
    "                    actionsIndices = None\n",
    "                    actionsLabels = []\n",
    "\n",
    "            #check n+1 exists\n",
    "            if(n+1 < len(maSum)):\n",
    "                #if n+1 exists but not 0 start an action\n",
    "                if(maSum[n+1] != 0):\n",
    "                    #start action including 0 at n\n",
    "                    actionsIndices = allJoints[k][n]\n",
    "                    actionsLabels.append(subsetLabels[k][n])\n",
    "                    started = True\n",
    "                #else ignore current index\n",
    "            #else we are at the end so ignore\n",
    "\n",
    "        else: #current index is not zero\n",
    "            if(started):\n",
    "                #here if started = True we are in middle of action so concatenate\n",
    "                actionsIndices = np.hstack((actionsIndices, allJoints[k][n]))\n",
    "                actionsLabels.append(subsetLabels[k][n])\n",
    "                if(n+1 == len(maSum)):\n",
    "                    actionsIdxList[k].append(actionsIndices)\n",
    "                    actionsLabelsList[k].append(actionsLabels)\n",
    "            else:\n",
    "                #here action has not started meaning a zero was not found\n",
    "                #this occurs if vector does not start with a zero\n",
    "                actionsIndices = allJoints[k][n]\n",
    "                actionsLabels.append(subsetLabels[k][n])\n",
    "                started = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for h in range(len(actionsIdxList)):\n",
    "    for p in actionsLabelsList[h]:\n",
    "        print p\n",
    "        print\n",
    "        print\n",
    "        print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#find maximum length vector for SAM\n",
    "maxLen = 0\n",
    "for n in actionsIdxList:\n",
    "    for k in n:\n",
    "        if(k.shape[0] > maxLen):\n",
    "            maxLen = k.shape[0]\n",
    "\n",
    "# print maxLen\n",
    "\n",
    "#create Y and L\n",
    "Y = None\n",
    "L = []\n",
    "for n in range(len(actionsIdxList)):\n",
    "    for k in range(len(actionsIdxList[n])):\n",
    "        currLen = len(actionsIdxList[n][k])\n",
    "        augMat = np.zeros(maxLen-currLen)\n",
    "        if(Y == None): \n",
    "            Y = np.hstack((actionsIdxList[n][k],augMat))\n",
    "        else:\n",
    "            Y = np.vstack((Y, np.hstack((actionsIdxList[n][k],augMat))))\n",
    "        L.append(actionsLabelsList[n][k])\n",
    "print Y.shape\n",
    "print len(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import operator\n",
    "\n",
    "def most_common(L):\n",
    "    # get an iterable of (item, iterable) pairs\n",
    "    SL = sorted((x, i) for i, x in enumerate(L))\n",
    "    # print 'SL:', SL\n",
    "    groups = itertools.groupby(SL, key=operator.itemgetter(0))\n",
    "    # auxiliary function to get \"quality\" for an item\n",
    "    def _auxfun(g):\n",
    "        item, iterable = g\n",
    "        count = 0\n",
    "        min_index = len(L)\n",
    "        for _, where in iterable:\n",
    "            count += 1\n",
    "            min_index = min(min_index, where)\n",
    "            # print 'item %r, count %r, minind %r' % (item, count, min_index)\n",
    "        return count, -min_index\n",
    "    # pick the highest-count/earliest item\n",
    "    return max(groups, key=_auxfun)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L2 = [most_common(sublist) for sublist in L]\n",
    "\n",
    "Larr = np.zeros(len(L2))\n",
    "for f in range(len(L2)):\n",
    "    Larr[f] = labels.index(L2[f])\n",
    "\n",
    "print labels\n",
    "print Larr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class AR_Driver(SAMDriver):\n",
    "    def testing(self, testInstance):\n",
    "        # Returns the predictive mean, the predictive variance and the axis (pp) of the latent space backwards mapping.            \n",
    "        #mm,vv,pp=self.SAMObject.pattern_completion(testFace, visualiseInfo=visualiseInfo)\n",
    "        ret=self.SAMObject.pattern_completion(testInstance, visualiseInfo=None)\n",
    "\n",
    "        mm = ret[0]\n",
    "        vv = ret[1]\n",
    "        post = ret[3]        \n",
    "\n",
    "        # find nearest neighbour of mm and SAMObject.model.X\n",
    "        dists = np.zeros((self.SAMObject.model.X.shape[0],1))\n",
    "\n",
    "        for j in range(dists.shape[0]):\n",
    "            dists[j,:] = distance.euclidean(self.SAMObject.model.X.mean[j,:], mm[0].values)\n",
    "        nn, min_value = min(enumerate(dists), key=operator.itemgetter(1))\n",
    "        if self.SAMObject.type == 'mrd':\n",
    "            print \"With \" + str(vv.mean()) +\" prob. error the new action is \" + labels[int(self.SAMObject.model.bgplvms[1].Y[nn,:])]\n",
    "            textStringOut=labels[int(self.SAMObject.model.bgplvms[1].Y[nn,:])]\n",
    "\n",
    "        elif self.SAMObject.type == 'bgplvm':\n",
    "            print \"With \" + str(vv.mean()) +\" prob. error the new action is \" + labels[int(self.L[nn,:])]\n",
    "            textStringOut=labels[int(self.L[nn,:])]\n",
    "\n",
    "        if(vv.mean()<0.00012):            \n",
    "            print \"The action is \" + textStringOut\n",
    "        elif(vv.mean()>0.00012):\n",
    "            print \"I think the action is \" + textStringOut + \" but I am not sure\"      \n",
    "\n",
    "        # # Plot the training NN of the test image (the NN is found in the INTERNAl, compressed (latent) memory space!!!)\n",
    "        # if visualiseInfo is not None:\n",
    "        #     fig_nn = visualiseInfo['fig_nn']\n",
    "        #     fig_nn = pb.figure(11)\n",
    "        #     pb.title('Training NN')\n",
    "        #     fig_nn.clf()\n",
    "        #     pl_nn = fig_nn.add_subplot(111)\n",
    "        #     pl_nn.imshow(numpy.reshape(self.SAMObject.recall(nn),(self.imgHeightNew, self.imgWidthNew)), cmap=plt.cm.Greys_r)\n",
    "        #     pb.title('Training NN')\n",
    "        #     pb.show()\n",
    "        #     pb.draw()\n",
    "        #     pb.waitforbuttonpress(0.1)\n",
    "        #return pp\n",
    "\n",
    "        return ret[2]\n",
    "    \n",
    "    def readData(self, root_data_dir, participant_index, Y, L):\n",
    "        self.Y = Y\n",
    "        self.L = L[:,None]\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mySAMpy = AR_Driver()\n",
    "mySAMpy.readData(0,0,Y,Larr)\n",
    "\n",
    "Ntr = int(len(mySAMpy.L)*40/100)\n",
    "model_type = 'mrd'\n",
    "model_num_inducing = 35\n",
    "model_num_iterations = 100 #100\n",
    "model_init_iterations = 300 #800\n",
    "save_model=True\n",
    "economy_save = True\n",
    "visualise_output=True\n",
    "experiment_number = 1\n",
    "fname = '/home/daniel/WYSIWYD_PROJECT/actionRecognitionDataset/model/mAR_exp' + str(experiment_number)\n",
    "\n",
    "[Yall,Lall,YtestAll,LtestAll] = mySAMpy.prepareData(model_type, Ntr,randSeed=experiment_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mySAMpy.training(model_num_inducing, model_num_iterations, model_init_iterations, fname, save_model, economy_save)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss = [];\n",
    "sstest = [];\n",
    "print\n",
    "\n",
    "print 'Yall = ' + str(Yall.shape)\n",
    "print 'Lall = ' + str(Lall.shape)\n",
    "print 'YtestAll = ' + str(YtestAll.shape)\n",
    "print 'LtestAll = ' + str(LtestAll.shape)\n",
    "\n",
    "currTestData = YtestAll[0][None,:]\n",
    "currLabel = LtestAll[0]\n",
    "\n",
    "print 'curData = ' + str(currTestData.shape) \n",
    "print 'curLabel = ' + str(currLabel)\n",
    "print 'curAction truth = ' + labels[int(currLabel)]\n",
    "\n",
    "\n",
    "pp = mySAMpy.testing(currTestData)\n",
    "print pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'result' + str(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "t = yarp.Network.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
